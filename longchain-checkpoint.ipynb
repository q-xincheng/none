{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a641bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Jupyter使用的Python路径： d:\\jupt\\envs\\ai_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"当前Jupyter使用的Python路径：\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454ea6cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 导入必要模块\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage, AIMessage\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "# 导入必要模块\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 配置智谱API\n",
    "chat = ChatOpenAI(\n",
    "    api_key=\"ab4a94e66976427b8a96105a30a3be50.dOlgGiSkXxaCI6ie\", \n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\", \n",
    "    model=\"glm-4.5-flash\",  # 免费模型\n",
    "    max_retries=3,  # 重试次数\n",
    "    temperature=0.5  # 随机性：0-1，越小越稳定\n",
    ")\n",
    "\n",
    "# 测试连接是否成功\n",
    "test_message = [HumanMessage(content=\"你好，请回复'API连接成功'\")]\n",
    "response = chat.invoke(test_message)\n",
    "print(response.content)  # 预期输出：API连接成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d1b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 导入旧版LLM接口\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# 初始化LLM\n",
    "llm = OpenAI(\n",
    "    api_key=\"你的智谱API_KEY\",\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    model=\"glm-4.5-flash\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 调用LLM（输入为字符串）\n",
    "llm_response = llm.invoke(\"给我讲个简短的笑话\")\n",
    "print(\"LLM返回类型：\", type(llm_response))  # 输出：<class 'str'>\n",
    "print(\"LLM返回内容：\", llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1aac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 输入为消息列表（带角色区分）\n",
    "chat_messages = [\n",
    "    SystemMessage(content=\"你是一个爱说冷笑话的助手\"),\n",
    "    HumanMessage(content=\"给我讲个简短的笑话\")\n",
    "]\n",
    "\n",
    "# 调用ChatModel\n",
    "chat_response = chat.invoke(chat_messages)\n",
    "print(\"ChatModel返回类型：\", type(chat_response))  # 输出：<class 'langchain_core.messages.ai.AIMessage'>\n",
    "print(\"ChatModel返回内容：\", chat_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3d0b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 固定内容，修改需改代码\n",
    "fixed_messages = [\n",
    "    SystemMessage(content=\"你是一个翻译助手，请将用户输入翻译成中文\"),\n",
    "    HumanMessage(content=\"Hello, how are you?\")\n",
    "]\n",
    "\n",
    "fixed_response = chat.invoke(fixed_messages)\n",
    "print(\"硬编码翻译结果：\", fixed_response.content)  # 预期输出：你好，你好吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4d97d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 1. 定义模板（含变量占位符）\n",
    "translation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个翻译助手，请将用户输入翻译成{target_language}\"),\n",
    "    (\"human\", \"{source_text}\")\n",
    "])\n",
    "\n",
    "# 2. 组装链（模板 → 模型 → 解析器）\n",
    "translation_chain = translation_template | chat | StrOutputParser()\n",
    "\n",
    "# 3. 场景1：翻译成中文\n",
    "scene1 = translation_chain.invoke({\n",
    "    \"target_language\": \"中文\",\n",
    "    \"source_text\": \"I love programming.\"\n",
    "})\n",
    "print(\"场景1（中译）：\", scene1)  # 预期输出：我喜欢编程。\n",
    "\n",
    "# 4. 场景2：翻译成日语\n",
    "scene2 = translation_chain.invoke({\n",
    "    \"target_language\": \"日语\",\n",
    "    \"source_text\": \"I love programming.\"\n",
    "})\n",
    "print(\"场景2（日译）：\", scene2)  # 预期输出：プログラミングが好きです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb2ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 无解析器写法\n",
    "no_parser_messages = [\n",
    "    SystemMessage(content=\"你是一个爱说冷笑话的助手\"),\n",
    "    HumanMessage(content=\"给我讲个笑话\")\n",
    "]\n",
    "no_parser_response = chat.invoke(no_parser_messages)\n",
    "print(\"无解析器返回类型：\", type(no_parser_response))  # AIMessage对象\n",
    "print(\"无解析器返回内容：\", no_parser_response.content)\n",
    "\n",
    "# 有解析器写法\n",
    "parser = StrOutputParser()\n",
    "# 组装链：模型 → 解析器\n",
    "parser_chain = chat | parser\n",
    "parser_response = parser_chain.invoke(no_parser_messages)\n",
    "print(\"有解析器返回类型：\", type(parser_response))  # str类型\n",
    "print(\"有解析器返回内容：\", parser_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7adeb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 1. 定义小红书推文模板\n",
    "note_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"你是一个资深的小红书博主。请帮我为【{product}】写一篇推文。\n",
    "要求：\n",
    "1. 标题要足够吸睛，带上emoji\n",
    "2. 正文要分段，多用“家人们”“绝绝子”等语气词\n",
    "3. 结尾加上3个相关的Hashtag\"\"\"),\n",
    "    (\"human\", \"产品特点包括：{features}\")\n",
    "])\n",
    "\n",
    "# 2. 组装完整链\n",
    "note_chain = note_template | chat | StrOutputParser()\n",
    "\n",
    "# 3. 填充参数并运行\n",
    "note_result = note_chain.invoke({\n",
    "    \"product\": \"无线蓝牙耳机\",\n",
    "    \"features\": \"续航24小时、降噪效果好、颜值高、价格亲民\"\n",
    "})\n",
    "\n",
    "# 4. 输出结果\n",
    "print(\"小红书推文生成结果：\")\n",
    "print(note_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a882aa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# 1. 定义样本集（输入-输出示例）\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"帮我创建一个名为 web-server 的 Ubuntu 实例\",\n",
    "        \"output\": \"aliyun ecs RunInstances --InstanceName web-server --ImageId ubuntu_latest\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"查询所有运行中的服务器\",\n",
    "        \"output\": \"aliyun ecs DescribeInstances --Status Running\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"重启 id 为 i-abc12345 的机器\",\n",
    "        \"output\": \"aliyun ecs RebootInstance --InstanceId i-abc12345\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. 定义样本格式\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# 3. 构建少样本模板\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 4. 组装最终提示词\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个阿里云CLI助手。请严格参考示例，将用户的自然语言转换为aliyun命令行代码。不要解释，直接输出命令。\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# 5. 组装链并运行\n",
    "cli_chain = final_prompt | chat | StrOutputParser()\n",
    "cli_result = cli_chain.invoke({\"user_input\": \"我想把 web-server 这台机器停掉\"})\n",
    "print(\"自然语言转CLI命令结果：\", cli_result)  # 预期输出：aliyun ecs StopInstance --InstanceName web-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30da0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# 1. 准备资料库（向量存储）\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings(\n",
    "        api_key=\"你的智谱API_KEY\",\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 2. 转换为检索器\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. 定义并行处理链（分流输入）\n",
    "setup_and_retrieval = RunnableParallel({\n",
    "    \"context\": retriever,  # 检索相关资料\n",
    "    \"question\": RunnablePassthrough()  # 保留原始问题\n",
    "})\n",
    "\n",
    "# 4. 定义回答模板\n",
    "rag_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# 5. 组装完整RAG链\n",
    "rag_chain = setup_and_retrieval | rag_prompt | chat | StrOutputParser()\n",
    "\n",
    "# 6. 调用RAG链\n",
    "rag_result = rag_chain.invoke(\"where did harrison work?\")\n",
    "print(\"RAG回答结果：\", rag_result)  # 预期输出：Harrison worked at Kensho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cdd35",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 1. 定义笑话生成模板\n",
    "joke_prompt = ChatPromptTemplate.from_template(\"用一句话讲一个关于{topic}的笑话\")\n",
    "\n",
    "# 2. 组装链\n",
    "joke_chain = joke_prompt | chat | StrOutputParser()\n",
    "\n",
    "# 3. 准备批量数据\n",
    "batch_topics = [\n",
    "    {\"topic\": \"程序员\"},\n",
    "    {\"topic\": \"猫\"},\n",
    "    {\"topic\": \"外星人\"}\n",
    "]\n",
    "\n",
    "# 4. 批量处理（控制并发量为2）\n",
    "print(\"--- 开始并发批量处理 ---\")\n",
    "batch_results = joke_chain.batch(batch_topics, config={\"max_concurrency\": 2})\n",
    "\n",
    "# 5. 输出结果\n",
    "for i, result in enumerate(batch_results, 1):\n",
    "    print(f\"[{i}] {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581e774",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 1. 定义诗歌生成模板\n",
    "poem_prompt = ChatPromptTemplate.from_template(\"请给我写一首关于{topic}的短诗，大概50个字左右\")\n",
    "\n",
    "# 2. 组装链\n",
    "poem_chain = poem_prompt | chat | StrOutputParser()\n",
    "\n",
    "# 3. 流式调用（逐字输出）\n",
    "print(\"--- 开始流式生成（观察字逐个出现） ---\")\n",
    "for chunk in poem_chain.stream({\"topic\": \"秋天\"}):\n",
    "    print(chunk, end=\"\", flush=True)  # 不换行+强制刷新\n",
    "    time.sleep(0.1)  # 放慢速度便于观察\n",
    "print(\"\\n--- 流式生成结束 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
